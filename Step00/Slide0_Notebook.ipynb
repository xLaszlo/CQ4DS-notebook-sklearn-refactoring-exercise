{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.preprocessing import one_hot_encoder\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "engine = create_engine('sqlite:///../data/titanic.db')\n",
        "sqlite_connection = engine.connect()\n",
        "pd.read_sql('SELECT * FROM sqlite_schema WHERE type=\"table\"', con=sqlite_connection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "df = pd.read_sql('SELECT * FROM tbl_passengers', con=sqlite_connection)\n",
        "\n",
        "targets = pd.read_sql('SELECT * FROM tbl_targets', con=sqlite_connection)\n",
        "\n",
        "# df, targets = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
        "\n",
        "# parch = Parents/Children, sibsp = Siblings/Spouses\n",
        "df['family_size'] = df['parch'] + df['sibsp']\n",
        "df['is_alone'] = [1 if family_size==1 else 0 for family_size in df['family_size']]\n",
        "\n",
        "df['title'] = [name.split(',')[1].split('.')[0].strip() for name in df['name']]\n",
        "rare_titles = {k for k,v in Counter(df['title']).items() if v < 10}\n",
        "df['title'] = ['rare' if title in rare_titles else title for title in df['title']]\n",
        "\n",
        "df = df[[\n",
        "    'pclass', 'sex', 'age', 'ticket', 'family_size',\n",
        "    'fare', 'embarked', 'is_alone', 'title'\n",
        "]]\n",
        "\n",
        "targets = [int(v) for v in targets['is_survived']]\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, targets, stratify=targets, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_categorical = X_train[['embarked', 'sex', 'pclass', 'title', 'is_alone']]\n",
        "X_test_categorical = X_test[['embarked', 'sex', 'pclass', 'title', 'is_alone']]\n",
        "\n",
        "one_hot_encoder = one_hot_encoder(handle_unknown='ignore', sparse=False).fit(X_train_categorical)\n",
        "X_train_categorical_one_hot = one_hot_encoder.transform(X_train_categorical)\n",
        "X_test_categorical_one_hot = one_hot_encoder.transform(X_test_categorical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_numerical = X_train[['age', 'fare', 'family_size']]\n",
        "X_test_numerical = X_test[['age', 'fare', 'family_size']]\n",
        "knn_imputer = KNNImputer(n_neighbors=5).fit(X_train_numerical)\n",
        "X_train_numerical_imputed = knn_imputer.transform(X_train_numerical)\n",
        "X_test_numerical_imputed = knn_imputer.transform(X_test_numerical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "robust_scaler = RobustScaler().fit(X_train_numerical_imputed)\n",
        "X_train_numerical_imputed_scaled = robust_scaler.transform(X_train_numerical_imputed)\n",
        "X_test_numerical_imputed_scaled = robust_scaler.transform(X_test_numerical_imputed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_processed = np.hstack((X_train_categorical_one_hot, X_train_numerical_imputed_scaled))\n",
        "X_test_processed = np.hstack((X_test_categorical_one_hot, X_test_numerical_imputed_scaled))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = LogisticRegression(random_state=0).fit(X_train_processed, y_train)\n",
        "y_train_estimation = model.predict(X_train_processed)\n",
        "y_test_estimation = model.predict(X_test_processed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm_train = confusion_matrix(y_train, y_train_estimation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm_test = confusion_matrix(y_test, y_test_estimation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def do_test(filename, data):\n",
        "    if not os.path.isfile(filename):\n",
        "        pickle.dump(data, open(filename, 'wb'))\n",
        "    truth = pickle.load(open(filename, 'rb'))\n",
        "    try:\n",
        "        np.testing.assert_almost_equal(data, truth)\n",
        "        print(f'{filename} test passed')\n",
        "    except AssertionError as ex:\n",
        "        print(f'{filename} test failed {ex}')\n",
        "    \n",
        "do_test('../data/cm_test.pkl', cm_test)\n",
        "do_test('../data/cm_train.pkl', cm_train)\n",
        "do_test('../data/X_train_processed.pkl', X_train_processed)\n",
        "do_test('../data/X_test_processed.pkl', X_test_processed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def do_pandas_test(filename, data):\n",
        "    if not os.path.isfile(filename):\n",
        "        data.to_pickle(filename)\n",
        "    truth = pd.read_pickle(filename)\n",
        "    try:\n",
        "        pd.testing.assert_frame_equal(data, truth)\n",
        "        print(f'{filename} pandas test passed')\n",
        "    except AssertionError as ex:\n",
        "        print(f'{filename} pandas test failed {ex}')\n",
        "        \n",
        "# df['title'] = ['asd' for v in df['title']]\n",
        "do_pandas_test('../data/df.pkl', df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rare_titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
