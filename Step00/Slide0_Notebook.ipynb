{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>tbl_name</th>\n",
       "      <th>rootpage</th>\n",
       "      <th>sql</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>table</td>\n",
       "      <td>tbl_passengers</td>\n",
       "      <td>tbl_passengers</td>\n",
       "      <td>2</td>\n",
       "      <td>CREATE TABLE tbl_passengers (\\n\\tpid BIGINT, \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>table</td>\n",
       "      <td>tbl_targets</td>\n",
       "      <td>tbl_targets</td>\n",
       "      <td>35</td>\n",
       "      <td>CREATE TABLE tbl_targets (\\n\\tpid BIGINT, \\n\\t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type            name        tbl_name  rootpage  \\\n",
       "0  table  tbl_passengers  tbl_passengers         2   \n",
       "1  table     tbl_targets     tbl_targets        35   \n",
       "\n",
       "                                                 sql  \n",
       "0  CREATE TABLE tbl_passengers (\\n\\tpid BIGINT, \\...  \n",
       "1  CREATE TABLE tbl_targets (\\n\\tpid BIGINT, \\n\\t...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine('sqlite:///../data/titanic.db')\n",
    "sqlite_connection = engine.connect()\n",
    "pd.read_sql('SELECT * FROM sqlite_schema WHERE type=\"table\"', con=sqlite_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "df = pd.read_sql('SELECT * FROM tbl_passengers', con=sqlite_connection)\n",
    "\n",
    "targets = pd.read_sql('SELECT * FROM tbl_targets', con=sqlite_connection)\n",
    "\n",
    "# df, targets = fetch_openml(\"titanic\", version=1, as_frame=True, return_X_y=True)\n",
    "\n",
    "# parch = Parents/Children, sibsp = Siblings/Spouses\n",
    "df['family_size'] = df['parch'] + df['sibsp']\n",
    "df['is_alone'] = [1 if family_size==1 else 0 for family_size in df['family_size']]\n",
    "\n",
    "df['title'] = [name.split(',')[1].split('.')[0].strip() for name in df['name']]\n",
    "rare_titles = {k for k,v in Counter(df['title']).items() if v < 10}\n",
    "df['title'] = ['rare' if title in rare_titles else title for title in df['title']]\n",
    "\n",
    "df = df[[\n",
    "    'pclass', 'sex', 'age', 'ticket', 'family_size',\n",
    "    'fare', 'embarked', 'is_alone', 'title'\n",
    "]]\n",
    "\n",
    "targets = [int(v) for v in targets['is_survived']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, targets, stratify=targets, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_categorical = X_train[['embarked', 'sex', 'pclass', 'title', 'is_alone']]\n",
    "X_test_categorical = X_test[['embarked', 'sex', 'pclass', 'title', 'is_alone']]\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False).fit(X_train_categorical)\n",
    "X_train_categorical_one_hot = one_hot_encoder.transform(X_train_categorical)\n",
    "X_test_categorical_one_hot = one_hot_encoder.transform(X_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_numerical = X_train[['age', 'fare', 'family_size']]\n",
    "X_test_numerical = X_test[['age', 'fare', 'family_size']]\n",
    "knn_imputer = KNNImputer(n_neighbors=5).fit(X_train_numerical)\n",
    "X_train_numerical_imputed = knn_imputer.transform(X_train_numerical)\n",
    "X_test_numerical_imputed = knn_imputer.transform(X_test_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_scaler = RobustScaler().fit(X_train_numerical_imputed)\n",
    "X_train_numerical_imputed_scaled = robust_scaler.transform(X_train_numerical_imputed)\n",
    "X_test_numerical_imputed_scaled = robust_scaler.transform(X_test_numerical_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_processed = np.hstack((X_train_categorical_one_hot, X_train_numerical_imputed_scaled))\n",
    "X_test_processed = np.hstack((X_test_categorical_one_hot, X_test_numerical_imputed_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=0).fit(X_train_processed, y_train)\n",
    "y_train_estimation = model.predict(X_train_processed)\n",
    "y_test_estimation = model.predict(X_test_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train = confusion_matrix(y_train, y_train_estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_test = confusion_matrix(y_test, y_test_estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[553,  94],\n",
       "       [107, 293]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[142,  20],\n",
       "       [ 22,  78]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/cm_test.pkl test passed\n",
      "../data/cm_train.pkl test passed\n",
      "../data/X_train_processed.pkl test passed\n",
      "../data/X_test_processed.pkl test passed\n"
     ]
    }
   ],
   "source": [
    "def do_test(filename, data):\n",
    "    if not os.path.isfile(filename):\n",
    "        pickle.dump(data, open(filename, 'wb'))\n",
    "    truth = pickle.load(open(filename, 'rb'))\n",
    "    try:\n",
    "        np.testing.assert_almost_equal(data, truth)\n",
    "        print(f'{filename} test passed')\n",
    "    except AssertionError as ex:\n",
    "        print(f'{filename} test failed {ex}')\n",
    "    \n",
    "do_test('../data/cm_test.pkl', cm_test)\n",
    "do_test('../data/cm_train.pkl', cm_train)\n",
    "do_test('../data/X_train_processed.pkl', X_train_processed)\n",
    "do_test('../data/X_test_processed.pkl', X_test_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/df.pkl pandas test passed\n"
     ]
    }
   ],
   "source": [
    "def do_pandas_test(filename, data):\n",
    "    if not os.path.isfile(filename):\n",
    "        data.to_pickle(filename)\n",
    "    truth = pd.read_pickle(filename)\n",
    "    try:\n",
    "        pd.testing.assert_frame_equal(data, truth)\n",
    "        print(f'{filename} pandas test passed')\n",
    "    except AssertionError as ex:\n",
    "        print(f'{filename} pandas test failed {ex}')\n",
    "        \n",
    "# df['title'] = ['asd' for v in df['title']]\n",
    "do_pandas_test('../data/df.pkl', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Capt',\n",
       " 'Col',\n",
       " 'Don',\n",
       " 'Dona',\n",
       " 'Dr',\n",
       " 'Jonkheer',\n",
       " 'Lady',\n",
       " 'Major',\n",
       " 'Mlle',\n",
       " 'Mme',\n",
       " 'Ms',\n",
       " 'Rev',\n",
       " 'Sir',\n",
       " 'the Countess'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rare_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "774712da715a3086605d6bf08e7144a3a7e717b0d5585da12e288357dd4c8f07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
